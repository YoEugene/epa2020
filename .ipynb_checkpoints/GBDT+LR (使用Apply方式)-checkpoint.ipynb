{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # 快速操作结构数组的工具\n",
    "import matplotlib.pyplot as plt  # 可视化绘制\n",
    "from sklearn.linear_model import LinearRegression  # 线性回归\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score,roc_curve,auc\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./data/North/中山站/12/gbdt_2015_2018.csv')\n",
    "# df = df[df.columns.drop(list(df.filter(regex='AVG')))]\n",
    "# df = df[['PM2.5_TARGET', 'PM2.5_AVG12', 'PM2.5_AVG6', 'DAY_OF_YEAR', 'PM2.5_AVG3', 'HOUR', 'PM2.5_DIVTSQR_T1', 'PM2.5_AVG72', 'PM2.5_T11', 'PM2.5_T1', 'MONTH', 'RH_T1', 'PM10_AVG72', 'NO2_AVG72', 'SO2_AVG72', 'PM2.5_DIVTSQR_T2', 'O3_AVG24', 'RH_T2', 'CH4_DIVTSQR_T1', 'O3_AVG72', 'CH4_AVG3', 'CH4_AVG72', 'PM10_AVG24', 'PM2.5_T12', 'CH4_T1', 'NO_AVG72', 'PM2.5_AVG24', 'CH4_T2', 'CO_AVG72', 'SO2_AVG12', 'AMB_TEMP_T2', 'NO_AVG24', 'SO2_AVG24', 'CH4_DIVTSQR_T2', 'WIND_SPEED_T1', 'NOx_AVG72', 'AMB_TEMP_T1', 'AMB_TEMP_T3', 'RH_T4', 'AMB_TEMP_T12', 'CO_AVG24', 'PM2.5_DIVTSQR_T10', 'WEEKDAY', 'THC_AVG12', 'NOx_AVG24', 'RH_T12', 'AMB_TEMP_T10', 'O3_AVG12', 'AMB_TEMP_T5', 'AMB_TEMP_T11', 'CH4_AVG6', 'PM2.5_T10', 'CH4_AVG24', 'RH_T3', 'THC_AVG72', 'NO2_AVG24', 'SO2_AVG6', 'WS_HR_T1', 'CH4_AVG12', 'PM10_AVG12', 'NO2_AVG12', 'CO_T14', 'PM10_AVG6', 'PM10_T1', 'PM10_T12', 'O3_T27', 'PM2.5_T36', 'AMB_TEMP_T4', 'RH_T11', 'NO_AVG12', 'PM10_T26', 'NMHC_AVG72', 'PM10_T27', 'O3_AVG3', 'WD_HR_T1', 'PM10_T35', 'PM2.5_T35', 'SO2_AVG3', 'THC_T1', 'RH_T10', 'RH_T9', 'WIND_SPEED_T3', 'PM10_T21', 'AMB_TEMP_T8', 'CH4_T3', 'CO_AVG12', 'PM2.5_T13', 'PM2.5_DIVTSQR_T12', 'AMB_TEMP_T9', 'PM2.5_T33', 'PM2.5_T4', 'SO2_T33', 'O3_AVG6', 'THC_AVG24', 'NO2_T34', 'NO2_T36', 'NOx_AVG12', 'PM10_T36', 'PM10_T34', 'PM10_DIVTSQR_T1', 'RH_T7', 'AMB_TEMP_T6', 'PM10_AVG3', 'O3_T13', 'SO2_T1', 'SO2_T36', 'NO2_T13', 'RH_T5', 'NO_T21', 'PM10_T31', 'NMHC_AVG24', 'O3_T28', 'O3_DIVTSQR_T1', 'AMB_TEMP_T7', 'PM10_T28', 'SO2_DIVTSQR_T1', 'SO2_T23', 'SO2_T32', 'NO2_AVG6', 'PM2.5_T32', 'PM10_DIVTSQR_T11', 'NMHC_AVG6', 'SO2_T31', 'PM2.5_DIVTSQR_T3', 'NO2_T16', 'SO2_T24', 'PM10_DIVTSQR_T5', 'SO2_T35', 'PM2.5_T30', 'SO2_DIVTSQR_T8', 'PM2.5_T28', 'SO2_T34', 'PM10_T24', 'WIND_DIREC_T2', 'PM2.5_DIVTSQR_T11', 'NO_T22', 'PM10_T14', 'O3_T1', 'CO_T20', 'PM10_T23', 'NO_T20', 'NO_T15', 'PM2.5_T2', 'THC_AVG6', 'PM10_T30', 'NO_AVG6', 'PM10_T11', 'SO2_T28', 'O3_T22', 'PM10_T32', 'WIND_SPEED_T2', 'SO2_T26', 'WD_HR_T3', 'PM10_T15', 'PM2.5_T27', 'O3_DIVTSQR_T4', 'PM10_T5', 'SO2_T22', 'NO2_T31', 'SO2_T15','WS_HR_T11', 'PM2.5_T24', 'WD_HR_T4', 'NO_AVG3', 'WIND_SPEED_T12', 'O3_DIVTSQR_T12', 'SO2_T21', 'PM10_T3', 'O3_T26', 'PM10_T8', 'SO2_T20', 'SO2_T13', 'O3_T15', 'PM10_DIVTSQR_T6', 'WS_HR_T2', 'O3_T29', 'PM10_T4', 'NO_T19', 'NO_T13', 'WD_HR_T12', 'NO_T24', 'SO2_DIVTSQR_T7', 'WS_HR_T8', 'O3_T25', 'CO_T13', 'SO2_T10', 'CO_T28', 'O3_T19', 'CO_T36', 'WD_HR_T7', 'PM10_T13', 'NO_T14', 'WD_HR_T11', 'SO2_T17', 'RH_T6', 'NO_T10', 'PM2.5_T15', 'PM2.5_T31', 'RH_T8', 'PM2.5_DIVTSQR_T5', 'NOx_T36']]\n",
    "\n",
    "X_train, y_train = df.drop(['PM2.5_TARGET'], axis=1), df['PM2.5_TARGET']\n",
    "\n",
    "df_test = pd.read_csv('./data/North/中山站/12/gbdt_2019.csv')\n",
    "# df_test = df_test[df_test.columns.drop(list(df_test.filter(regex='AVG')))]\n",
    "# df_test = df_test[['PM2.5_TARGET', 'PM2.5_AVG12', 'PM2.5_AVG6', 'DAY_OF_YEAR', 'PM2.5_AVG3', 'HOUR', 'PM2.5_DIVTSQR_T1', 'PM2.5_AVG72', 'PM2.5_T11', 'PM2.5_T1', 'MONTH', 'RH_T1', 'PM10_AVG72', 'NO2_AVG72', 'SO2_AVG72', 'PM2.5_DIVTSQR_T2', 'O3_AVG24', 'RH_T2', 'CH4_DIVTSQR_T1', 'O3_AVG72', 'CH4_AVG3', 'CH4_AVG72', 'PM10_AVG24', 'PM2.5_T12', 'CH4_T1', 'NO_AVG72', 'PM2.5_AVG24', 'CH4_T2', 'CO_AVG72', 'SO2_AVG12', 'AMB_TEMP_T2', 'NO_AVG24', 'SO2_AVG24', 'CH4_DIVTSQR_T2', 'WIND_SPEED_T1', 'NOx_AVG72', 'AMB_TEMP_T1', 'AMB_TEMP_T3', 'RH_T4', 'AMB_TEMP_T12', 'CO_AVG24', 'PM2.5_DIVTSQR_T10', 'WEEKDAY', 'THC_AVG12', 'NOx_AVG24', 'RH_T12', 'AMB_TEMP_T10', 'O3_AVG12', 'AMB_TEMP_T5', 'AMB_TEMP_T11', 'CH4_AVG6', 'PM2.5_T10', 'CH4_AVG24', 'RH_T3', 'THC_AVG72', 'NO2_AVG24', 'SO2_AVG6', 'WS_HR_T1', 'CH4_AVG12', 'PM10_AVG12', 'NO2_AVG12', 'CO_T14', 'PM10_AVG6', 'PM10_T1', 'PM10_T12', 'O3_T27', 'PM2.5_T36', 'AMB_TEMP_T4', 'RH_T11', 'NO_AVG12', 'PM10_T26', 'NMHC_AVG72', 'PM10_T27', 'O3_AVG3', 'WD_HR_T1', 'PM10_T35', 'PM2.5_T35', 'SO2_AVG3', 'THC_T1', 'RH_T10', 'RH_T9', 'WIND_SPEED_T3', 'PM10_T21', 'AMB_TEMP_T8', 'CH4_T3', 'CO_AVG12', 'PM2.5_T13', 'PM2.5_DIVTSQR_T12', 'AMB_TEMP_T9', 'PM2.5_T33', 'PM2.5_T4', 'SO2_T33', 'O3_AVG6', 'THC_AVG24', 'NO2_T34', 'NO2_T36', 'NOx_AVG12', 'PM10_T36', 'PM10_T34', 'PM10_DIVTSQR_T1', 'RH_T7', 'AMB_TEMP_T6', 'PM10_AVG3', 'O3_T13', 'SO2_T1', 'SO2_T36', 'NO2_T13', 'RH_T5', 'NO_T21', 'PM10_T31', 'NMHC_AVG24', 'O3_T28', 'O3_DIVTSQR_T1', 'AMB_TEMP_T7', 'PM10_T28', 'SO2_DIVTSQR_T1', 'SO2_T23', 'SO2_T32', 'NO2_AVG6', 'PM2.5_T32', 'PM10_DIVTSQR_T11', 'NMHC_AVG6', 'SO2_T31', 'PM2.5_DIVTSQR_T3', 'NO2_T16', 'SO2_T24', 'PM10_DIVTSQR_T5', 'SO2_T35', 'PM2.5_T30', 'SO2_DIVTSQR_T8', 'PM2.5_T28', 'SO2_T34', 'PM10_T24', 'WIND_DIREC_T2', 'PM2.5_DIVTSQR_T11', 'NO_T22', 'PM10_T14', 'O3_T1', 'CO_T20', 'PM10_T23', 'NO_T20', 'NO_T15', 'PM2.5_T2', 'THC_AVG6', 'PM10_T30', 'NO_AVG6', 'PM10_T11', 'SO2_T28', 'O3_T22', 'PM10_T32', 'WIND_SPEED_T2', 'SO2_T26', 'WD_HR_T3', 'PM10_T15', 'PM2.5_T27', 'O3_DIVTSQR_T4', 'PM10_T5', 'SO2_T22', 'NO2_T31', 'SO2_T15','WS_HR_T11', 'PM2.5_T24', 'WD_HR_T4', 'NO_AVG3', 'WIND_SPEED_T12', 'O3_DIVTSQR_T12', 'SO2_T21', 'PM10_T3', 'O3_T26', 'PM10_T8', 'SO2_T20', 'SO2_T13', 'O3_T15', 'PM10_DIVTSQR_T6', 'WS_HR_T2', 'O3_T29', 'PM10_T4', 'NO_T19', 'NO_T13', 'WD_HR_T12', 'NO_T24', 'SO2_DIVTSQR_T7', 'WS_HR_T8', 'O3_T25', 'CO_T13', 'SO2_T10', 'CO_T28', 'O3_T19', 'CO_T36', 'WD_HR_T7', 'PM10_T13', 'NO_T14', 'WD_HR_T11', 'SO2_T17', 'RH_T6', 'NO_T10', 'PM2.5_T15', 'PM2.5_T31', 'RH_T8', 'PM2.5_DIVTSQR_T5', 'NOx_T36']]\n",
    "X_test, y_test = df_test.drop(['PM2.5_TARGET'], axis=1), df_test['PM2.5_TARGET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PM2.5_T1</th>\n",
       "      <th>PM2.5_T2</th>\n",
       "      <th>PM2.5_T3</th>\n",
       "      <th>PM2.5_T4</th>\n",
       "      <th>PM2.5_T5</th>\n",
       "      <th>PM2.5_T6</th>\n",
       "      <th>PM2.5_T7</th>\n",
       "      <th>PM2.5_T8</th>\n",
       "      <th>PM2.5_T9</th>\n",
       "      <th>PM2.5_T10</th>\n",
       "      <th>...</th>\n",
       "      <th>SO2_AVG12</th>\n",
       "      <th>SO2_AVG24</th>\n",
       "      <th>THC_AVG3</th>\n",
       "      <th>THC_AVG6</th>\n",
       "      <th>THC_AVG12</th>\n",
       "      <th>THC_AVG24</th>\n",
       "      <th>DAY_OF_YEAR</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>WEEKDAY</th>\n",
       "      <th>MONTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>8712.000000</td>\n",
       "      <td>8712.000000</td>\n",
       "      <td>8712.000000</td>\n",
       "      <td>8712.000000</td>\n",
       "      <td>8712.000000</td>\n",
       "      <td>8712.000000</td>\n",
       "      <td>8712.000000</td>\n",
       "      <td>8712.000000</td>\n",
       "      <td>8712.000000</td>\n",
       "      <td>8712.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8712.000000</td>\n",
       "      <td>8712.000000</td>\n",
       "      <td>8712.000000</td>\n",
       "      <td>8712.000000</td>\n",
       "      <td>8712.000000</td>\n",
       "      <td>8712.000000</td>\n",
       "      <td>8712.000000</td>\n",
       "      <td>8712.000000</td>\n",
       "      <td>8712.000000</td>\n",
       "      <td>8712.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>14.432533</td>\n",
       "      <td>14.432877</td>\n",
       "      <td>14.433183</td>\n",
       "      <td>14.433413</td>\n",
       "      <td>14.432954</td>\n",
       "      <td>14.432609</td>\n",
       "      <td>14.432035</td>\n",
       "      <td>14.431576</td>\n",
       "      <td>14.431117</td>\n",
       "      <td>14.431232</td>\n",
       "      <td>...</td>\n",
       "      <td>2.123815</td>\n",
       "      <td>2.124070</td>\n",
       "      <td>1.980318</td>\n",
       "      <td>1.980314</td>\n",
       "      <td>1.980296</td>\n",
       "      <td>1.980181</td>\n",
       "      <td>183.000000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>3.002755</td>\n",
       "      <td>6.556474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>9.135846</td>\n",
       "      <td>9.135698</td>\n",
       "      <td>9.135538</td>\n",
       "      <td>9.135452</td>\n",
       "      <td>9.135977</td>\n",
       "      <td>9.136313</td>\n",
       "      <td>9.137000</td>\n",
       "      <td>9.137575</td>\n",
       "      <td>9.138149</td>\n",
       "      <td>9.137987</td>\n",
       "      <td>...</td>\n",
       "      <td>0.919699</td>\n",
       "      <td>0.750570</td>\n",
       "      <td>0.196492</td>\n",
       "      <td>0.184513</td>\n",
       "      <td>0.168581</td>\n",
       "      <td>0.150828</td>\n",
       "      <td>104.794691</td>\n",
       "      <td>6.922584</td>\n",
       "      <td>2.002178</td>\n",
       "      <td>3.432980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.075000</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>1.616667</td>\n",
       "      <td>1.641667</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.595833</td>\n",
       "      <td>1.866667</td>\n",
       "      <td>1.866667</td>\n",
       "      <td>1.875000</td>\n",
       "      <td>1.883333</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>6.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.950000</td>\n",
       "      <td>2.012500</td>\n",
       "      <td>1.933333</td>\n",
       "      <td>1.950000</td>\n",
       "      <td>1.950000</td>\n",
       "      <td>1.958333</td>\n",
       "      <td>183.000000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.575000</td>\n",
       "      <td>2.562500</td>\n",
       "      <td>2.033333</td>\n",
       "      <td>2.050000</td>\n",
       "      <td>2.041667</td>\n",
       "      <td>2.053385</td>\n",
       "      <td>274.000000</td>\n",
       "      <td>18.250000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.908333</td>\n",
       "      <td>6.258333</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>3.050000</td>\n",
       "      <td>2.850000</td>\n",
       "      <td>2.641667</td>\n",
       "      <td>364.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 528 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          PM2.5_T1     PM2.5_T2     PM2.5_T3     PM2.5_T4     PM2.5_T5  \\\n",
       "count  8712.000000  8712.000000  8712.000000  8712.000000  8712.000000   \n",
       "mean     14.432533    14.432877    14.433183    14.433413    14.432954   \n",
       "std       9.135846     9.135698     9.135538     9.135452     9.135977   \n",
       "min       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "25%       8.000000     8.000000     8.000000     8.000000     8.000000   \n",
       "50%      13.000000    13.000000    13.000000    13.000000    13.000000   \n",
       "75%      19.000000    19.000000    19.000000    19.000000    19.000000   \n",
       "max      83.000000    83.000000    83.000000    83.000000    83.000000   \n",
       "\n",
       "          PM2.5_T6     PM2.5_T7     PM2.5_T8     PM2.5_T9    PM2.5_T10  ...  \\\n",
       "count  8712.000000  8712.000000  8712.000000  8712.000000  8712.000000  ...   \n",
       "mean     14.432609    14.432035    14.431576    14.431117    14.431232  ...   \n",
       "std       9.136313     9.137000     9.137575     9.138149     9.137987  ...   \n",
       "min       1.000000     1.000000     1.000000     1.000000     1.000000  ...   \n",
       "25%       8.000000     8.000000     8.000000     8.000000     8.000000  ...   \n",
       "50%      13.000000    13.000000    13.000000    13.000000    13.000000  ...   \n",
       "75%      19.000000    19.000000    19.000000    19.000000    19.000000  ...   \n",
       "max      83.000000    83.000000    83.000000    83.000000    83.000000  ...   \n",
       "\n",
       "         SO2_AVG12    SO2_AVG24     THC_AVG3     THC_AVG6    THC_AVG12  \\\n",
       "count  8712.000000  8712.000000  8712.000000  8712.000000  8712.000000   \n",
       "mean      2.123815     2.124070     1.980318     1.980314     1.980296   \n",
       "std       0.919699     0.750570     0.196492     0.184513     0.168581   \n",
       "min      -0.075000     0.437500     1.600000     1.600000     1.616667   \n",
       "25%       1.500000     1.595833     1.866667     1.866667     1.875000   \n",
       "50%       1.950000     2.012500     1.933333     1.950000     1.950000   \n",
       "75%       2.575000     2.562500     2.033333     2.050000     2.041667   \n",
       "max       7.908333     6.258333     3.166667     3.050000     2.850000   \n",
       "\n",
       "         THC_AVG24  DAY_OF_YEAR         HOUR      WEEKDAY        MONTH  \n",
       "count  8712.000000  8712.000000  8712.000000  8712.000000  8712.000000  \n",
       "mean      1.980181   183.000000    12.500000     3.002755     6.556474  \n",
       "std       0.150828   104.794691     6.922584     2.002178     3.432980  \n",
       "min       1.641667     2.000000     1.000000     0.000000     1.000000  \n",
       "25%       1.883333    92.000000     6.750000     1.000000     4.000000  \n",
       "50%       1.958333   183.000000    12.500000     3.000000     7.000000  \n",
       "75%       2.053385   274.000000    18.250000     5.000000    10.000000  \n",
       "max       2.641667   364.000000    24.000000     6.000000    12.000000  \n",
       "\n",
       "[8 rows x 528 columns]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strategy = '往前找到最近數值填入'\n",
    "X_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1         136.0225           40.22s\n",
      "         2         130.8396           40.72s\n",
      "         3         126.2466           41.82s\n",
      "         4         122.5356           40.56s\n",
      "         5         118.9040           39.93s\n",
      "         6         116.0647           39.75s\n",
      "         7         113.3749           38.84s\n",
      "         8         111.0375           38.78s\n",
      "         9         109.0167           38.20s\n",
      "        10         107.2698           37.50s\n",
      "        20          96.0656           31.42s\n",
      "        30          90.6619           25.18s\n",
      "        40          87.2710           19.63s\n",
      "        50          84.8567           14.25s\n",
      "        60          83.0166            9.22s\n",
      "        70          81.5090            4.47s\n",
      "        80          80.1789            0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "                          learning_rate=0.1, loss='ls', max_depth=3,\n",
       "                          max_features=None, max_leaf_nodes=None,\n",
       "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                          min_samples_leaf=1, min_samples_split=2,\n",
       "                          min_weight_fraction_leaf=0.0, n_estimators=80,\n",
       "                          n_iter_no_change=None, presort='auto',\n",
       "                          random_state=None, subsample=1.0, tol=0.0001,\n",
       "                          validation_fraction=0.1, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 弱分类器的数目\n",
    "n_estimator = 80\n",
    "# 随机生成分类数据。\n",
    "# X, y = make_classification(n_samples=80000,n_features=20,n_classes=2)\n",
    "\n",
    "# 切分为测试集和训练集，比例0.5\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)\n",
    "# 将训练集切分为两部分，一部分用于训练GBDT模型，另一部分输入到训练好的GBDT模型生成GBDT特征，然后作为LR的特征。这样分成两部分是为了防止过拟合。\n",
    "X_train_gbdt, X_train_lr, y_train_gbdt, y_train_lr = train_test_split(X_train, y_train, test_size=0.5, random_state=42)\n",
    "# 调用GBDT分类模型。\n",
    "gbdt = GradientBoostingRegressor(n_estimators=n_estimator, verbose=1)\n",
    "# gbdt = GradientBoostingRegressor(verbose=1)\n",
    "# 调用one-hot编码。\n",
    "one_hot = OneHotEncoder()\n",
    "# 调用LR分类模型。\n",
    "# lr = LogisticRegression()\n",
    "lr = LinearRegression()\n",
    "\n",
    "'''使用X_train训练GBDT模型，后面用此模型构造特征'''\n",
    "gbdt.fit(X_train_gbdt, y_train_gbdt)\n",
    "# gbdt.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_leaf_index = gbdt.apply(X_train_gbdt)\n",
    "# X_leaf_index = gbdt.apply(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17484, 80)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_leaf_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_leaf_index = gbdt.apply(X_train_gbdt)[:, :, 0]\n",
    "X_leaf_index = gbdt.apply(X_train_gbdt)[:, :]\n",
    "# X_leaf_index = gbdt.apply(X_train)[:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17484, 80)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_leaf_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "每个样本在每个树中所属的叶子索引\n",
      " [[ 3.  4.  7. ...  3. 11. 13.]\n",
      " [10. 10. 11. ...  3.  4. 13.]\n",
      " [ 3.  3.  3. ...  3.  3. 10.]\n",
      " ...\n",
      " [ 4.  4. 10. ...  6. 11. 13.]\n",
      " [ 6.  6.  7. ...  3. 11. 14.]\n",
      " [ 4.  4. 10. ...  6.  3. 13.]]\n"
     ]
    }
   ],
   "source": [
    "X_lr_leaf_index = gbdt.apply(X_train_lr)[:, :] # apply返回每个样本在每科树中所属的叶子节点索引。行数为样本数，列数为树数目。值为在每个数的叶子索引\n",
    "# X_lr_leaf_index = gbdt.apply(X_train)[:, :] # apply返回每个样本在每科树中所属的叶子节点索引。行数为样本数，列数为树数目。值为在每个数的叶子索引\n",
    "print('每个样本在每个树中所属的叶子索引\\n',X_leaf_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.,  4.,  7., ...,  3., 11., 13.],\n",
       "       [10., 10., 11., ...,  3.,  4., 13.],\n",
       "       [ 3.,  3.,  3., ...,  3.,  3., 10.],\n",
       "       ...,\n",
       "       [ 4.,  4., 10., ...,  6., 11., 13.],\n",
       "       [ 6.,  6.,  7., ...,  3., 11., 14.],\n",
       "       [ 4.,  4., 10., ...,  6.,  3., 13.]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_leaf_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_leaf_index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yoeugene/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# fit one-hot编码器\n",
    "one_hot.fit(X_leaf_index)  # 训练one-hot编码，就是识别每列有多少可取值\n",
    "X_lr_one_hot = one_hot.transform(X_lr_leaf_index)  # 将训练数据，通过gbdt树，形成的叶子节点（每个叶子代表了原始特征的一种组合）索引，编码成one0-hot特征。\n",
    "# 编码后的每个特征代表原来的一批特征的组合。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X_lr_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34946     7.0\n",
       "21226    39.0\n",
       "32523    16.0\n",
       "10226    23.0\n",
       "33450    33.0\n",
       "         ... \n",
       "2478     38.0\n",
       "3800     15.0\n",
       "18059     9.0\n",
       "6900     15.0\n",
       "32257     7.0\n",
       "Name: PM2.5_TARGET, Length: 17484, dtype: float64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_lr\n",
    "# y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用逻辑回归训练GBDT组合特征的结果\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "使用训练好的GBDT模型构建特征，然后将特征经过one-hot编码作为新的特征输入到LR模型训练。\n",
    "'''\n",
    "\n",
    "# 使用lr训练gbdt的特征组合\n",
    "print('使用逻辑回归训练GBDT组合特征的结果')\n",
    "lr.fit(X_lr_one_hot, y_train_lr)\n",
    "# lr.fit(X_lr_one_hot, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "採用填缺值策略:往前找到最近數值填入\n",
      "Average MAE = 6.072580760123317\n"
     ]
    }
   ],
   "source": [
    "# 用训练好的LR模型多X_test做预测\n",
    "# y_pred_grd_lm = lr.predict_proba(one_hot.transform(gbdt.apply(X_test)[:, :, 0]))[:, 1]  # 获取测试集正样本的概率\n",
    "y_pred_grd_lm = lr.predict(one_hot.transform(gbdt.apply(X_test)[:, :]))[:]  # 获取测试集正样本的概率\n",
    "\n",
    "sum_of_absolute_err = sum(abs(y_pred_grd_lm - y_test))\n",
    "num_of_test_case = len(y_test)\n",
    "\n",
    "\n",
    "print('採用填缺值策略:' + strategy)\n",
    "print('Average MAE = ' + str(sum_of_absolute_err / num_of_test_case))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# y_pre= lr.predict(one_hot.transform(gbdt.apply(X_test)[:, :, 0]))  # 获取测试集正样本的概率\n",
    " \n",
    "# y_pro= lr.predict_proba(one_hot.transform(gbdt.apply(X_test)[:, :, 0]))[:, 1]  # 获取测试集正样本的概率\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import metrics\n",
    "\n",
    "\n",
    "# print(\"AUC Score :\",(metrics.roc_auc_score(y_test, y_pro)))   \n",
    "# print(\"Accuracy :\",(metrics.accuracy_score(y_test, y_pre)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
